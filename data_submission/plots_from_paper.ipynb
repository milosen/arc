{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218ed81c",
   "metadata": {},
   "source": [
    "## Plots from the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"axes.titlesize\"] = 14.\n",
    "mpl.rcParams[\"axes.labelsize\"] = 12.\n",
    "mpl.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "mpl.rcParams[\"axes.labelweight\"] = \"normal\"\n",
    "mpl.rcParams['font.sans-serif'] = \"Arial\"\n",
    "\n",
    "cm = 1/2.54  # centimeters in inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c12583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "tp_modes_pretty = [\"TP-random position-random\", \"TP-random position-fixed\", \"TP-structured\"]\n",
    "\n",
    "df = pd.read_csv(\"full_dataset.csv\")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(17*cm, 10*cm))\n",
    "sns.boxplot(df[df[\"Feature\"] == \"max\"], x=\"Stream TP mode\", y=\"PRI\", hue=\"Control\", order=tp_modes_pretty, gap=0.2)\n",
    "plt.title(\"Maximum PRI Across Features\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles, labels=labels)\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"results\", \"lexicon_pris_summary.pdf\"), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86faf394-48b3-4b77-a69c-3595116e2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axs = plt.subplots(3, 1, figsize=(17*cm, 20*cm), layout=\"tight\", sharex=True)\n",
    "labels = ['Controlled\\nlexicons (ARC)',\n",
    " 'Reference\\nlexicons (Literature)',\n",
    " 'Random\\nlexicons (Baseline)']\n",
    "\n",
    "for i, tp_mode in enumerate(tp_modes_pretty):\n",
    "    sns.boxplot(df[df[\"Stream TP mode\"] == tp_mode], x=\"Feature\", y=\"PRI\", hue=\"Control\", ax=axs[i], fliersize=1, gap=0.3)\n",
    "    axs[i].set_title(f\"Stream TP mode: {tp_mode}\", weight=\"normal\", size=12)\n",
    "    if i == 0:\n",
    "        axs[i].set(ylim=(-0.02, 0.4))\n",
    "        # axs[i].legend(labels)\n",
    "        # sns.move_legend(axs[i], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "        sns.move_legend(axs[i], \"upper left\")\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        axs[i].legend(handles=handles, labels=labels)\n",
    "        \n",
    "    else:\n",
    "        axs[i].legend([],[], frameon=False)\n",
    "locs, labls = plt.xticks()\n",
    "plt.xticks(locs, labls, rotation=60)\n",
    "plt.suptitle(f\"PRIs Across Features\", weight=\"bold\", size=14, x=0.55)\n",
    "plt.savefig(\"results/lexicon_pri.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a9c4c",
   "metadata": {},
   "source": [
    "## Visualization of Feature Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cedfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "# GLOBAL PARAMETERS\n",
    "nSyll = 12\n",
    "nTrip = 4\n",
    "nPoss = 3\n",
    "nReps = nTrip * 15\n",
    "\n",
    "# IMPORT MATRIX OF BINARY FEATURES FOR ALL IPA PHONEMES\n",
    "indir = 'arc/data/'\n",
    "fname = indir + 'phonemes.csv'\n",
    "fdata = list(csv.reader(open(fname, \"r\")))\n",
    "labls = fdata[0][1:]\n",
    "lbl_C = ['son', 'back', 'hi', 'lab', 'cor', 'cont', 'lat', 'nas', 'voi']\n",
    "lbl_V = ['back', 'hi', 'lo', 'lab', 'tense', 'long']\n",
    "phons = [i[0] for i in fdata[1:]]\n",
    "numbs = [i[1:] for i in fdata[1:]]\n",
    "nFeat = len(lbl_C) + len(lbl_V)\n",
    "\n",
    "# IMPORT STREAMS FROM TITONE, MILOSEVIC & MEYER (2024) ARC PACKAGE\n",
    "indir = ''\n",
    "fname = indir + 'best_lexicon.txt'\n",
    "fdata = list(csv.reader(open(fname, \"r\")))\n",
    "lexicon_words = fdata[0][0].split(\": \")[1].split(\"|\")\n",
    "lexicon_sylls = [list(map(''.join, zip(*[iter(i)]*nPoss))) for i in lexicon_words]\n",
    "TP_posrdm_arc = fdata[2][0].split(\": \")[1].split(\"|\")\n",
    "TP_struct_arc = fdata[7][0].split(\": \")[1].split(\"|\")\n",
    "TP_posfix_arc = fdata[12][0].split(\": \")[1].split(\"|\")\n",
    "TP_stream_arc = [TP_struct_arc, TP_posfix_arc, TP_posrdm_arc]\n",
    "TP_fnames_arc = ['TP_struct_ARC', 'TP_posfix_ARC', 'TP_posrdm_ARC']\n",
    "\n",
    "# IMPORT ONE REFERENCE LEXICON\n",
    "lexicon_reference = [['tu', 'pi', 'ro'],\n",
    "                     ['bi', 'da', 'ku'],\n",
    "                     ['토o', 'la', 'bu'],\n",
    "                     ['pa', 'do', 'ti']]\n",
    "Lexicons = [lexicon_sylls, lexicon_reference]\n",
    "\n",
    "# COMPUTE FEATURE MATRIX FOR EACH SYLLABLE IN THE LEXICON\n",
    "Feats_by_sylls_by_words = []\n",
    "Feats_by_sylls = []\n",
    "for iLexi in Lexicons:\n",
    "    feats_by_sylls_by_words = []\n",
    "    feats_by_sylls = []\n",
    "    for iWord in range(nTrip):\n",
    "        V = []\n",
    "        for iSyll in range(len(iLexi[iWord])):\n",
    "            sylli = iLexi[iWord][iSyll]\n",
    "            iCons = sylli[0]\n",
    "            iVows = sylli[1:]\n",
    "            fCons = numbs[phons.index(iCons)]\n",
    "            fVows = numbs[phons.index(iVows)]\n",
    "            nFeat = [i for i in range(len(labls)) if labls[i] in lbl_C]\n",
    "            v = []\n",
    "            for iFeat in nFeat:\n",
    "                if fCons[iFeat] == '+':\n",
    "                    v.append(1)\n",
    "                else:\n",
    "                    v.append(0)\n",
    "            nFeat = [i for i in range(len(labls)) if labls[i] in lbl_V]\n",
    "            for iFeat in nFeat:\n",
    "                if fVows[iFeat] == '+':\n",
    "                    v.append(1)\n",
    "                else:\n",
    "                    v.append(0)\n",
    "            V.append(v)\n",
    "            feats_by_sylls.append(v)\n",
    "        feats_by_sylls_by_words.append(np.transpose(np.matrix(V)))\n",
    "    Feats_by_sylls_by_words.append(feats_by_sylls_by_words)\n",
    "    Feats_by_sylls.append(feats_by_sylls)\n",
    "\n",
    "# EXTRACT FEATURE OVERLAP FOR WORDS IN THE LEXICON\n",
    "patts = [tuple([i for i in np.roll((1, 0, 0), j)]) for j in range(nPoss)]\n",
    "nFeat = len(lbl_C) + len(lbl_V)\n",
    "BB = []\n",
    "for iLexi in range(len(Lexicons)):\n",
    "    B = []\n",
    "    for iFeat in range(nFeat):\n",
    "        F = []\n",
    "        for iWord in range(nTrip):\n",
    "            F.append(Feats_by_sylls_by_words[iLexi][iWord][iFeat])\n",
    "        F = [tuple(i.tolist()[0]) for i in F]\n",
    "        D = dict((j, [i for i, k in enumerate(F) if k == j]) for j in set(F) if F.count(j) > 1)\n",
    "        I = set()\n",
    "        for key, val in D.items():\n",
    "            if key in patts:\n",
    "                for i in val:\n",
    "                    I.add(i)\n",
    "        if any(I):\n",
    "            B.append((iFeat, [i for i in I]))\n",
    "    BB.append(B)\n",
    "\n",
    "# FIGURE REPRESENTING BINARY FEATURE MATRIX FOR THE LEXICON WORDS (LAG = 3)\n",
    "L = [labls[i] for i in range(len(labls)) if labls[i] in lbl_C]\n",
    "L.extend([labls[i] for i in range(len(labls)) if labls[i] in lbl_V])\n",
    "C_a = [(0.0000, 0.4470, 0.7410), \n",
    "       (0.8500, 0.3250, 0.0980), \n",
    "       (0.9290, 0.6940, 0.1250), \n",
    "       (0.4940, 0.1840, 0.5560)]\n",
    "C_b = [(0.4660, 0.6740, 0.1880),\n",
    "       (0.3010, 0.7450, 0.9330),\n",
    "       (0.6350, 0.0780, 0.1840),\n",
    "       (0.4940, 0.3294, 0.6196)]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey = True)\n",
    "for iLexi in range(len(Lexicons)):\n",
    "    V = np.transpose(np.matrix(Feats_by_sylls[iLexi]))\n",
    "    G = np.zeros((V.shape[0],V.shape[1],3))\n",
    "    G[V == 1] = [1.0,1.0,1.0]\n",
    "    G[V == 0] = [0.5,0.5,0.5]\n",
    "    if iLexi == 0:\n",
    "        ax1.imshow(G, interpolation = 'nearest')\n",
    "    else:\n",
    "        ax2.imshow(G, interpolation = 'nearest')\n",
    "    for b in BB[iLexi]:\n",
    "        y_pos = b[0] - 0.5\n",
    "        y_width = 1\n",
    "        for l in b[1]:\n",
    "            x_pos = l*nPoss - 0.5\n",
    "            x_width = nPoss\n",
    "            r = patches.Rectangle((x_pos, y_pos), x_width, y_width,\n",
    "                                  linewidth = 3, edgecolor = 'r', facecolor = 'none')\n",
    "            if iLexi == 0:\n",
    "                ax1.add_patch(r)\n",
    "            else:\n",
    "                ax2.add_patch(r)\n",
    "fig.supxlabel('Syllables', x = 0.51, fontsize = 12, fontname = 'Arial')\n",
    "fig.supylabel('Features', fontsize = 12, fontname = 'Arial')\n",
    "fig.suptitle('Feature Overlap', x = 0.51, y = 0.95, \n",
    "             fontsize = 14, fontweight = 'bold', fontname = 'Arial')\n",
    "ax1.axhline(len(lbl_C) - 0.5, linestyle = '--', color = 'black')\n",
    "ax2.axhline(len(lbl_C) - 0.5, linestyle = '--', color = 'black')\n",
    "ax1.set_xlabel('ARC lexicon', fontsize = 12, fontname = 'Arial')\n",
    "ax2.set_xlabel('Reference lexicon', fontsize = 12, fontname = 'Arial')\n",
    "ax1.set_xticks(range(nSyll), [i for j in Lexicons[0] for i in j])\n",
    "ax2.set_xticks(range(nSyll), [i for j in Lexicons[1] for i in j])\n",
    "ax1.set_yticks(range(len(L)), L, fontname = 'Arial')\n",
    "ax1.tick_params(length = 0)\n",
    "ax2.tick_params(length = 0)\n",
    "for i in range(nPoss):\n",
    "    ax1.axvline(nPoss*(i+1)-0.5, linewidth = 2, linestyle = '--', color = C_a[i])\n",
    "    ax2.axvline(nPoss*(i+1)-0.5, linewidth = 2, linestyle = '--', color = C_b[i])\n",
    "for i in range(nTrip):\n",
    "    for j in range(nPoss):\n",
    "        ax1.get_xticklabels()[i*nPoss+j].set_color(C_a[i])\n",
    "        ax2.get_xticklabels()[i*nPoss+j].set_color(C_b[i])\n",
    "opdir = 'results/'\n",
    "f_out = opdir + 'feature_overlap.pdf'\n",
    "plt.show()\n",
    "fig.savefig(f_out, bbox_inches = 'tight', dpi = 600)\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bb13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fecfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%#################################################################################################\n",
    "############################### TRANSITIONAL PROBABILITY: STATISTICS (Figure 5) ###############################\n",
    "####################################################################################################\n",
    "from scipy import stats\n",
    "import pickle\n",
    "    \n",
    "# LOAD INCREMENTAL TP MATRIX FOR ALL STREAMS\n",
    "indir = ''\n",
    "fname = indir + 'Incremental_TPs.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    fdata = pickle.load(f)\n",
    "Incremental_TPs = fdata\n",
    "\n",
    "# PLOT INCREMENTAL TP MATRIX FOR ALL STREAMS\n",
    "opdir = 'results/'\n",
    "f_out = opdir + 'stream_TP_statistics.pdf'\n",
    "groups = [r'Shuffling', r'ARC PRW']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, layout = 'tight')\n",
    "y_ax1 = Incremental_TPs[1][0]\n",
    "y_ax3 = Incremental_TPs[1][1]\n",
    "ax1.scatter(range(len(y_ax1)), y_ax1, color = 'r')\n",
    "ax3.scatter(range(len(y_ax3)), y_ax3, color = 'r')\n",
    "y_ax1 = Incremental_TPs[0][2]\n",
    "y_ax2 = Incremental_TPs[0][1]\n",
    "y_ax3 = Incremental_TPs[0][0]\n",
    "ax1.scatter(range(len(y_ax1)), y_ax1, color = 'b')\n",
    "ax2.scatter(range(len(y_ax2)), y_ax2, color = 'b')\n",
    "ax3.scatter(range(len(y_ax3)), y_ax3, color = 'b')\n",
    "ax1.set_title(r'TP-random position-random', fontsize = 12, fontname = 'Arial')\n",
    "ax2.set_title(r'TP-random position-fixed', fontsize = 12, fontname = 'Arial')\n",
    "ax3.set_title(r'TP-structured', fontsize = 12, fontname = 'Arial')\n",
    "ax3.set_xlabel(r'Stream locations', fontsize = 12, fontname = 'Arial')\n",
    "ax2.set_ylabel(r'TPs', fontsize = 12, fontname = 'Arial')\n",
    "ax1.axhline(0.09, linestyle = '--', color = 'black')\n",
    "ax2.axhline(0.25, linestyle = '--', color = 'black')\n",
    "ax3.axhline(0.33, linestyle = '--', color = 'black')\n",
    "ax1.set_yticks([0.09, 1])\n",
    "ax2.set_yticks([0.25, 1])\n",
    "ax3.set_yticks([0.33, 1])\n",
    "ax1.set_xticks([])\n",
    "ax2.set_xticks([])\n",
    "ax1.set_ylim([0, 1])\n",
    "ax2.set_ylim([0, 1])\n",
    "ax3.set_ylim([0, 1])\n",
    "fig.suptitle('Incremental TPs', x = 0.55, y = 1, \n",
    "             fontsize = 14, fontname = 'Arial', fontweight = 'bold')\n",
    "fig.legend(groups, prop={'family':'Arial', 'size':12})\n",
    "plt.show()\n",
    "fig.savefig(f_out, bbox_inches = 'tight', dpi = 600)\n",
    "\n",
    "# RUN LEVENE TEST TO COMPARE VARIANCE OF TP MATRICES\n",
    "L_struct = stats.levene(Incremental_TPs[0][0][2::3], Incremental_TPs[1][1][2::3], center = 'mean')\n",
    "L_random = stats.levene(Incremental_TPs[0][2], Incremental_TPs[1][0], center = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from arc.phonecodes import phonecodes\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# READ SYLLABLES, FREQUENCIES AND PROBABILITIES FROM CORPUS AND CONVERT SYLLABLES TO IPA\n",
    "indir = 'arc/data/example_corpus/'\n",
    "fname = indir + 'syll.txt'\n",
    "fdata = list(csv.reader(open(fname, \"r\"), delimiter = '\\t'))\n",
    "sylls = [phonecodes.xsampa2ipa(i[1], 'deu') for i in fdata[1:]]\n",
    "freqs = [int(i[2]) for i in fdata[1:]]\n",
    "probs = [float(i[3]) for i in fdata[1:]]\n",
    "\n",
    "# LOAD GERMAN BIGRAMS\n",
    "indir = 'arc/data/example_corpus/'\n",
    "fname = indir + 'ipa_bigrams_german.csv'\n",
    "gram2 = list(csv.reader(open(fname, \"r\"), delimiter = '\\t'))\n",
    "gram2 = [i[0].split(\",\") for i in gram2][1:]\n",
    "freq2 = [int(i[2]) for i in gram2]\n",
    "\n",
    "# LOAD GERMAN TRIGRAMS\n",
    "indir = 'arc/data/example_corpus/'\n",
    "fname = indir + 'ipa_trigrams_german.csv'\n",
    "gram3 = list(csv.reader(open(fname, \"r\"), delimiter = '\\t'))\n",
    "gram3 = [i[0].split(\",\") for i in gram3][1:]\n",
    "freq3 = [int(i[1]) for i in gram3]\n",
    "\n",
    "# READ ORDER OF PHONEMES IN GERMAN WORDS\n",
    "indir = 'arc/data/example_corpus/'\n",
    "fname = indir + 'german_IPA_seg.csv'\n",
    "fdata = list(csv.reader(open(fname, \"r\"), delimiter = '\\t'))\n",
    "fdata = [i[0].split(\",\") for i in fdata][1:]\n",
    "fdata = [i for i in fdata if len(i) == 3]\n",
    "phonX = [i[1].replace('\"','') for i in fdata]\n",
    "phonX = [i.replace(\"g\",\"토\") for i in phonX]\n",
    "phonP = [int(i[2]) for i in fdata]\n",
    "\n",
    "# READ MATRIX OF BINARY FEATURES FOR ALL IPA PHONEMES\n",
    "indir = 'arc/data/'\n",
    "fname = indir + 'phonemes.csv'\n",
    "fdata = list(csv.reader(open(fname, \"r\")))\n",
    "labls = fdata[0][1:]\n",
    "phons = [i[0] for i in fdata[1:]]\n",
    "numbs = [i[1:] for i in fdata[1:]]\n",
    "cnsnt = [phons[i] for i in range(len(phons)) if numbs[i][labls.index('cons')] == '+']\n",
    "longV = [phons[i] for i in range(len(phons)) if numbs[i][labls.index('long')] == '+' \n",
    "                                             and phons[i] not in cnsnt]\n",
    "\n",
    "# SELECT CONSONANT-VOWEL SYLLABLES WITH LONG VOWEL LENGTH\n",
    "cvidx = [i for i in range(len(sylls)) if sylls[i].startswith(tuple(cnsnt))\n",
    "         and sylls[i].endswith(tuple(longV)) and len(sylls[i]) == 3]\n",
    "cvsyl = [sylls[i] for i in cvidx]\n",
    "cvfrq = [freqs[i] for i in cvidx]\n",
    "cvprb = [probs[i] for i in cvidx]\n",
    "\n",
    "# SELECT CV SYLLABLES WITH UNIFORM LOG-PROBABILITY OF OCCURRENCE IN THE CORPUS\n",
    "CVidx = [i for i in range(len(cvfrq)) \n",
    "         if stats.uniform.sf(abs(stats.zscore(np.log(cvfrq))))[i] > 0.05 \n",
    "         and cvsyl[i][0] in phonX]\n",
    "CVsyl = [cvsyl[i] for i in CVidx]\n",
    "CVfrq = [cvfrq[i] for i in CVidx]\n",
    "CVprb = [cvprb[i] for i in CVidx]\n",
    "\n",
    "# SELECT BIGRAMS WITH UNIFORM LOG-PROBABILITY OF OCCURRENCE IN THE CORPUS\n",
    "frx_2 = [i for i in range(len(freq2))\n",
    "          if stats.uniform.sf(abs(stats.zscore(np.log(freq2))))[i] > 0.05]\n",
    "gram2 = [i[1].replace(\"_\", \"\") for i in gram2]\n",
    "gram2 = [i.replace(\"g\",\"토\") for i in gram2]\n",
    "Gram2 = [gram2[i] for i in frx_2]\n",
    "Freq2 = [freq2[i] for i in frx_2]\n",
    "\n",
    "# SELECT TRIGRAMS WITH UNIFORM LOG-PROBABILITY OF OCCURRENCE IN THE CORPUS\n",
    "frx_3 = [i for i in range(len(freq3))\n",
    "          if stats.uniform.sf(abs(stats.zscore(np.log(freq3))))[i] > 0.05]\n",
    "gram3 = [i[0].replace(\"_\", \"\") for i in gram3]\n",
    "gram3 = [i.replace(\"g\",\"토\") for i in gram3]\n",
    "Gram3 = [gram3[i] for i in frx_3]\n",
    "Freq3 = [freq3[i] for i in frx_3]\n",
    "\n",
    "# PLOT N-GRAM FREQUENCY DISTRIBUTION OF SYLLABLES AND PHONEMES\n",
    "opdir = 'results/'\n",
    "f_out = opdir + 'ngram_frequency_distributions.pdf'\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, layout = \"constrained\")\n",
    "\n",
    "# SYLLABLES FREQUENCY DISTRIBUTION\n",
    "ax1.plot(freqs, color = 'black')\n",
    "ax1.set_title('Unigrams', fontsize = 12, fontname = 'Arial')\n",
    "ax1.set_xticks((0, len(freqs)))\n",
    "ax1.set_yticks((0, freqs[0]))\n",
    "ax1.set_ylabel('Syllable/Phoneme' + '\\n' + 'Frequency', fontsize = 12, fontname = 'Arial')\n",
    "\n",
    "# BIGRAM FREQUENCY DISTRIBUTION\n",
    "ax2.plot(freq2, color = 'black')\n",
    "ax2.set_title('Bigrams', fontsize = 12, fontname = 'Arial')\n",
    "ax2.set_xticks((0, len(freq2)))\n",
    "ax2.set_yticks((0, freq2[0]))\n",
    "ax2.set_xlabel('Rank', fontsize = 12, fontname = 'Arial')\n",
    "\n",
    "# TRIGRAM FREQUENCY DISTRIBUTION\n",
    "ax3.plot(freq3, color = 'black')\n",
    "ax3.set_title('Trigrams', fontsize = 12, fontname = 'Arial')\n",
    "ax3.set_xticks((0, len(freq3)))\n",
    "ax3.set_yticks((0, freq3[0]))\n",
    "\n",
    "# SYLLABLES UNIFORMITY TEST\n",
    "ax4.plot(stats.uniform.sf(abs(stats.zscore(np.log(cvfrq)))), color = 'black')\n",
    "ax4.axhline(0.05, linestyle = '--', color = 'black')\n",
    "ax4.invert_xaxis()\n",
    "ax4.set_xticks((CVidx[0], CVidx[-1]), (cvfrq[CVidx[0]], cvfrq[CVidx[-1]]))\n",
    "ax4.set_yticks([0.05, 1.0])\n",
    "ax4.set_ylabel('Uniformity Test' + '\\n' + '(p-values)', fontsize = 12, fontname = 'Arial')\n",
    "\n",
    "# BIGRAM UNIFORMITY TEST\n",
    "ax5.plot(stats.uniform.sf(abs(stats.zscore(np.log(freq2)))), color = 'black')\n",
    "ax5.axhline(0.05, linestyle = '--', color = 'black')\n",
    "ax5.invert_xaxis()\n",
    "ax5.set_xticks((frx_2[0], frx_2[-1]), (freq2[frx_2[0]], freq2[frx_2[-1]]))\n",
    "ax5.set_yticks([0.05, 1.0])\n",
    "ax5.set_xlabel('Frequency', fontsize = 12, fontname = 'Arial')\n",
    "\n",
    "# TRIGRAM UNIFORMITY TEST\n",
    "ax6.plot(stats.uniform.sf(abs(stats.zscore(np.log(freq3)))), color = 'black')\n",
    "ax6.axhline(0.05, linestyle = '--', color = 'black')\n",
    "ax6.invert_xaxis()\n",
    "ax6.set_xticks((frx_3[0], frx_3[-1]), (freq3[frx_3[0]], freq3[frx_3[-1]]))\n",
    "ax6.set_yticks([0.05, 1.0])\n",
    "\n",
    "# ADJUST AND SAVE\n",
    "fig.suptitle('Frequency Distributions', x = 0.56, y = 1.1, \n",
    "             fontsize = 14, fontname = 'Arial', fontweight = 'bold')\n",
    "fig.align_ylabels((ax1, ax4))\n",
    "plt.show()\n",
    "fig.savefig(f_out, bbox_inches = 'tight', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021bffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
