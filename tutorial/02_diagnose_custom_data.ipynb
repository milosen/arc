{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b0859a1-27fb-4496-b4fd-f87ab45ea567",
   "metadata": {},
   "source": [
    "# Use your own data\n",
    "\n",
    "In this tutorial, we discuss two ways of using your own data:\n",
    "\n",
    "1. You have one or more lexicons you want to evaluate and generate streams with\n",
    "2. You already have streams and just want to evaluate them\n",
    "\n",
    "If you want to expand ARC, we are happy to invite you to contribute to the [ARC Project](https://github.com/milosen/arc) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa8e43d8-f3f3-4d6b-a756-bb8bb96fc67a",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Loading/creating your custom lexicon\n",
    "\n",
    "Let's say you have a lexicon consisting of the (pseudo-)words 'piɾuta', 'baɡoli', 'tokuda, and 'ɡuhaɪbo'.\n",
    "\n",
    "We assume you have prepared your lexicon as a list of lists (see below), and that all syllables are of the same type. The function `to_lexicon()` accepts the syllable types we call 'cv' and 'cV'. 'cv' is a syllable consisting of a single-character consonant and a short vowel, e.g. 'pi'. Because it is common in the literature, 'cv' also allows diphthongs, e.g. 'haɪ'). The 'cV' type is a single-character consonant, together with a long vowel, e.g. 'tuː'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b20f17a-ff7b-46cf-bc4c-7f341ba8adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon: piɾuta|baɡoli|tokuda|ɡuhaɪbo\n",
      "\n",
      "syllables_info: {'syllable_feature_labels': [['son', 'back', 'hi', 'lab', 'cor', 'cont', 'lat', 'nas', 'voi'], ['back', 'hi', 'lo', 'lab', 'tense', 'long']], 'syllable_type': 'cv'}\n",
      "cumulative_feature_repetitiveness: 7\n",
      "max_pairwise_feature_repetitiveness: 2\n"
     ]
    }
   ],
   "source": [
    "from arc import to_lexicon\n",
    "import numpy as np\n",
    "\n",
    "raw_lexicon = [\n",
    "  ['pi', 'ɾu', 'ta'],\n",
    "  ['ba', 'ɡo', 'li'],\n",
    "  ['to', 'ku', 'da'],\n",
    "  ['ɡu', 'haɪ', 'bo']\n",
    "]\n",
    "\n",
    "lexicon = to_lexicon(raw_lexicon, syllable_type=\"cv\")\n",
    "\n",
    "print(\"Lexicon:\", lexicon)\n",
    "print(\"\")\n",
    "\n",
    "for key, value in lexicon.info.items():\n",
    "    print(f\"{key}:\", lexicon.info[key])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19210d47-441f-43fc-ac87-c7eee58252b7",
   "metadata": {},
   "source": [
    "### 1.1. Custom Lexicon: Moving upstream\n",
    "\n",
    "Now we \"move upstream\" in the generation process. We turn the lexicon into a stream using the standard `arc` functions introduced earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e8de424-9c86-40a3-b709-32ad6278ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streams (summary): piɾutabaɡolitokudaɡuhaɪbo_random|piɾutabaɡolitokudaɡuhaɪbo_word_structured|piɾutabaɡolitokudaɡuhaɪbo_position_controlled\n",
      "\n",
      "tp_modes: ('random', 'word_structured', 'position_controlled')\n",
      "max_rhythmicity: None\n",
      "max_tries_randomize: 10\n",
      "stream_length: 32\n",
      "require_all_tp_modes: True\n"
     ]
    }
   ],
   "source": [
    "from arc import make_streams\n",
    "streams = make_streams([lexicon])\n",
    "\n",
    "print(\"Streams (summary):\", streams)\n",
    "print(\"\")\n",
    "\n",
    "for key, value in streams.info.items():\n",
    "    print(f\"{key}:\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d839edd9-9d33-423b-a22c-e99be09edc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream (random):  ku|pi|li|bo|ɡu|to|haɪ|ba|da|ɾu|ɡo|ta|ɡo|da|ku|ta|ɾu|ba|li|to|bo|pi|haɪ|ɡu|ba|bo|haɪ|da|ta|pi|to|li|ɾu|ɡu|ku|ɡo|ba|ɡu|ɾu|pi|bo|li|ɡo|ku|to|da|haɪ|ta|ɡu|li|da|to|ɾu|bo|ku|ba|haɪ|ɡo|pi|ta|li|ta|ku|ɾu|to|ɡo|haɪ|pi|ɡu|bo|da|ba|ta|ba|pi|ku|haɪ|bo|ɾu|li|ɡu|da|ɡo|to|ta|bo|ɡo|ɡu|pi|ɾu|haɪ|to|ba|ku|da|li|ba|ɡo|bo|to|ku|li|pi|da|ɡu|ta|haɪ|ɾu|da|bo|ba|ɾu|ta|to|pi|ɡo|li|haɪ|ku|ɡu|ɡo|ɾu|ku|bo|ta|da|pi|ba|to|ɡu|haɪ|li|ku|ɡu|pi|li|ɾu|haɪ|to|ɡo|ta|ba|bo|da|li|ɡu|ɡo|bo|to|ku|da|pi|haɪ|ba|ta|ɾu|to|li|pi|bo|ɡu|ba|ɡo|ɾu|ku|haɪ|da|ta|li|ba|da|ɾu|ɡu|haɪ|ta|ku|bo|ɡo|to|pi|ɡu|li|ɡo|pi|ɾu|da|bo|ba|to|ta|haɪ|ku|li|bo|haɪ|ɾu|ta|ɡu|ku|ɡo|ba|pi|da|to|da|ku|pi|to|haɪ|ɡo|ɡu|bo|ɾu|ba|li|ta|ɡo|da|ɡu|ta|to|bo|ku|ɾu|pi|ba|haɪ|li|haɪ|pi|ɡo|li|ku|ba|ɡu|to|ɾu|bo|ta|da|haɪ|ɡu|da|ba|ɾu|ɡo|ku|to|ta|pi|li|bo|li|da|ɡo|haɪ|bo|pi|ta|ba|ku|ɾu|ɡu|to|ɡu|ɾu|li|to|ba|haɪ|da|pi|ku|ta|bo|ɡo|ɾu|ɡo|ɡu|bo|li|ba|da|ta|haɪ|to|pi|ku|ɡo|ku|ta|bo|haɪ|ɾu|to|da|ɡu|pi|ba|li|ɡo|ta|ɾu|li|to|bo|ɡu|ku|da|ba|pi|haɪ|ku|ɡu|ba|ɾu|da|bo|to|ɡo|pi|ta|li|haɪ|ɡo|li|ta|da|haɪ|bo|pi|ɡu|ɾu|ku|to|ba|ɡu|ɡo|to|haɪ|ba|ta|ku|pi|da|li|ɾu|bo|ɾu|ta|ɡu|haɪ|pi|to|li|ku|ba|bo|da|ɡo|ba|ɡo|haɪ|ɡu|ta|pi|bo|ku|li|da|to|ɾu|haɪ|li|pi|ɡo|bo|ta|to|ɡu|da|ɾu|ba|ku\n",
      "PRIs:\n",
      "  phon_1_son 0.10846560846560846\n",
      "  phon_1_back 0.05291005291005291\n",
      "  phon_1_hi 0.05291005291005291\n",
      "  phon_1_lab 0.07936507936507936\n",
      "  phon_1_cor 0.10052910052910052\n",
      "  phon_1_cont 0.10846560846560846\n",
      "  phon_1_lat 0.007936507936507936\n",
      "  phon_1_nas 0.0\n",
      "  phon_1_voi 0.042328042328042326\n",
      "  phon_2_back 0.0\n",
      "  phon_2_hi 0.04497354497354497\n",
      "  phon_2_lo 0.06349206349206349\n",
      "  phon_2_lab 0.03968253968253968\n",
      "  phon_2_tense 0.0\n",
      "  phon_2_long 0.0\n",
      "Max PRI across features: phon_1_son 0.10846560846560846\n",
      "Cummulative PRI across features: 0.7010582010582009\n",
      " \n",
      "Stream (word_structured):  ba|ɡo|li|ɡu|haɪ|bo|to|ku|da|pi|ɾu|ta|ɡu|haɪ|bo|ba|ɡo|li|pi|ɾu|ta|to|ku|da|ba|ɡo|li|to|ku|da|ɡu|haɪ|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|pi|ɾu|ta|ɡu|haɪ|bo|pi|ɾu|ta|to|ku|da|ba|ɡo|li|ɡu|haɪ|bo|to|ku|da|ɡu|haɪ|bo|ba|ɡo|li|pi|ɾu|ta|ba|ɡo|li|ɡu|haɪ|bo|pi|ɾu|ta|to|ku|da|ɡu|haɪ|bo|ba|ɡo|li|to|ku|da|pi|ɾu|ta|ɡu|haɪ|bo|to|ku|da|ba|ɡo|li|pi|ɾu|ta|ba|ɡo|li|pi|ɾu|ta|to|ku|da|ɡu|haɪ|bo|to|ku|da|pi|ɾu|ta|ɡu|haɪ|bo|ba|ɡo|li|ɡu|haɪ|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|haɪ|bo|pi|ɾu|ta|to|ku|da|ba|ɡo|li|pi|ɾu|ta|ɡu|haɪ|bo|to|ku|da|ba|ɡo|li|to|ku|da|pi|ɾu|ta|ba|ɡo|li|ɡu|haɪ|bo|pi|ɾu|ta|ɡu|haɪ|bo|ba|ɡo|li|to|ku|da|pi|ɾu|ta|to|ku|da|ɡu|haɪ|bo|ba|ɡo|li|pi|ɾu|ta|ba|ɡo|li|ɡu|haɪ|bo|to|ku|da|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|haɪ|bo|to|ku|da|ba|ɡo|li|ɡu|haɪ|bo|pi|ɾu|ta|to|ku|da|ba|ɡo|li|pi|ɾu|ta|ɡu|haɪ|bo|to|ku|da|ɡu|haɪ|bo|pi|ɾu|ta|ba|ɡo|li|ɡu|haɪ|bo|to|ku|da|pi|ɾu|ta|ba|ɡo|li|to|ku|da|pi|ɾu|ta|ɡu|haɪ|bo|ba|ɡo|li|pi|ɾu|ta|ɡu|haɪ|bo|ba|ɡo|li|to|ku|da|ba|ɡo|li|pi|ɾu|ta|ɡu|haɪ|bo|to|ku|da|pi|ɾu|ta|to|ku|da|ɡu|haɪ|bo|ba|ɡo|li|ɡu|haɪ|bo|pi|ɾu|ta|to|ku|da|ba|ɡo|li|ɡu|haɪ|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ba|ɡo|li|pi|ɾu|ta|to|ku|da|ɡu|haɪ|bo|to|ku|da|ɡu|haɪ|bo|pi|ɾu|ta|ba|ɡo|li|pi|ɾu|ta|to|ku|da|ba|ɡo|li|ɡu|haɪ|bo\n",
      "PRIs:\n",
      "  phon_1_son 0.1402116402116402\n",
      "  phon_1_back 0.14814814814814814\n",
      "  phon_1_hi 0.14814814814814814\n",
      "  phon_1_lab 0.12698412698412698\n",
      "  phon_1_cor 0.04497354497354497\n",
      "  phon_1_cont 0.1402116402116402\n",
      "  phon_1_lat 0.0\n",
      "  phon_1_nas 0.0\n",
      "  phon_1_voi 0.013227513227513227\n",
      "  phon_2_back 0.0\n",
      "  phon_2_hi 0.015873015873015872\n",
      "  phon_2_lo 0.09259259259259259\n",
      "  phon_2_lab 0.1402116402116402\n",
      "  phon_2_tense 0.0\n",
      "  phon_2_long 0.0\n",
      "Max PRI across features: phon_1_back 0.14814814814814814\n",
      "Cummulative PRI across features: 1.0105820105820107\n",
      " \n",
      "Stream (position_controlled):  ɡu|ɾu|li|ba|haɪ|ta|pi|ɡo|da|to|ku|bo|pi|ɾu|bo|ba|ku|li|to|haɪ|da|ɡu|ɡo|ta|ɡu|haɪ|bo|to|ɡo|li|pi|ku|da|ba|ɾu|ta|ba|ɡo|bo|ɡu|ku|ta|to|ɾu|da|pi|haɪ|li|ɡu|ku|li|ba|ɡo|bo|to|haɪ|ta|pi|ɾu|da|ba|ɾu|ta|ɡu|haɪ|da|pi|ɡo|li|to|ku|bo|ɡu|ɡo|da|to|ɾu|li|pi|haɪ|bo|ba|ku|ta|to|ɡo|ta|ba|haɪ|li|ɡu|ɾu|bo|pi|ku|da|ɡu|ɡo|bo|pi|haɪ|li|to|ku|ta|ba|ɾu|da|ba|ku|da|pi|ɾu|ta|to|ɡo|li|ɡu|haɪ|bo|to|ɾu|bo|ba|haɪ|ta|ɡu|ku|li|pi|ɡo|da|to|haɪ|da|ɡu|ɾu|li|ba|ɡo|ta|pi|ku|bo|ɡu|ɾu|da|pi|ɡo|bo|to|ku|li|ba|haɪ|ta|ɡu|ku|ta|to|haɪ|da|ba|ɡo|li|pi|ɾu|bo|ba|ɾu|li|to|ɡo|ta|pi|ku|da|ɡu|haɪ|bo|pi|haɪ|li|ɡu|ɡo|da|to|ɾu|ta|ba|ku|bo|ɡu|ɡo|bo|pi|ku|da|to|ɾu|ta|ba|haɪ|li|ɡu|ɾu|bo|to|haɪ|da|ba|ku|li|pi|ɡo|ta|to|ɡo|li|ba|ɾu|da|pi|haɪ|bo|ɡu|ku|ta|pi|ɾu|li|to|ku|bo|ba|ɡo|da|ɡu|haɪ|ta|ɡu|haɪ|li|ba|ɾu|bo|pi|ɡo|ta|to|ku|da|ɡu|ku|ta|ba|ɡo|da|pi|haɪ|bo|to|ɾu|li|to|haɪ|ta|pi|ɾu|da|ba|ku|li|ɡu|ɡo|bo|ba|haɪ|da|to|ɡo|li|pi|ku|bo|ɡu|ɾu|ta|ɡu|ku|li|to|haɪ|ta|ba|ɾu|da|pi|ɡo|bo|to|ɡo|li|ba|ku|bo|pi|haɪ|da|ɡu|ɾu|ta|ɡu|haɪ|li|pi|ɾu|bo|ba|ɡo|da|to|ku|ta|to|ɾu|li|ɡu|ɡo|ta|pi|ku|da|ba|haɪ|bo|ɡu|haɪ|ta|pi|ɡo|li|to|ku|da|ba|ɾu|bo|pi|ku|ta|ɡu|ɡo|bo|to|ɾu|li|ba|haɪ|da|ɡu|ku|bo|ba|ɡo|da|pi|ɾu|ta|to|haɪ|li|pi|haɪ|bo|ɡu|ɾu|da|to|ɡo|ta|ba|ku|li\n",
      "PRIs:\n",
      "  phon_1_son 0.10317460317460317\n",
      "  phon_1_back 0.14285714285714285\n",
      "  phon_1_hi 0.14285714285714285\n",
      "  phon_1_lab 0.09788359788359788\n",
      "  phon_1_cor 0.1164021164021164\n",
      "  phon_1_cont 0.10317460317460317\n",
      "  phon_1_lat 0.007936507936507936\n",
      "  phon_1_nas 0.0\n",
      "  phon_1_voi 0.007936507936507936\n",
      "  phon_2_back 0.0\n",
      "  phon_2_hi 0.05291005291005291\n",
      "  phon_2_lo 0.0582010582010582\n",
      "  phon_2_lab 0.12698412698412698\n",
      "  phon_2_tense 0.0\n",
      "  phon_2_long 0.0\n",
      "Max PRI across features: phon_1_back 0.14285714285714285\n",
      "Cummulative PRI across features: 0.9603174603174602\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for stream in streams:\n",
    "    tp_mode = stream.info['stream_tp_mode']\n",
    "    pris = stream.info['rhythmicity_indexes']\n",
    "    \n",
    "    print(f\"Stream ({tp_mode}): \", stream)\n",
    "    print(\"PRIs:\")\n",
    "    max = \"phon_1_son\"\n",
    "    cum = 0\n",
    "    for feat, pri in stream.info[\"rhythmicity_indexes\"].items():\n",
    "        print(\" \", feat, pri)\n",
    "        if pri > stream.info[\"rhythmicity_indexes\"][max]:\n",
    "            max = feat\n",
    "        cum += pri\n",
    "\n",
    "    print(\"Max PRI across features:\", max, stream.info[\"rhythmicity_indexes\"][max])\n",
    "    print(\"Cummulative PRI across features:\", cum)\n",
    "    print(\" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "703f58eb-7992-4622-a894-489101abbd8b",
   "metadata": {},
   "source": [
    "### 1.2. Custom Lexicon: Moving backwards"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e248df26-3b8e-45a7-858a-6cebcf62b602",
   "metadata": {},
   "source": [
    "\"moving backwards\" in the generation process, i.e. generating words, syllables, and phonemes is less common, but we got you covered. Let's say you want to compare the syllables in your custom lexicon with the arc corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdde46cd-93cd-4f21-9d46-d8a5ff6f93ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|... (12 elements total)\n"
     ]
    }
   ],
   "source": [
    "syllables = lexicon.flatten()\n",
    "print(syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5f30f0-4488-432a-824a-524c8dc65d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi|ta|ba|ɡo|li|to|ku|da|ɡu|haɪ|... (11 elements total)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'binary_features': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " 'phonotactic_features': [['plo', 'lab'], ['i']],\n",
       " 'freq': 70,\n",
       " 'prob': 6.92628e-05}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arc.io import read_syllables_corpus\n",
    "\n",
    "corpus_syllables = read_syllables_corpus()\n",
    "\n",
    "syllables_with_corpus_stats = syllables.intersection(corpus_syllables)\n",
    "\n",
    "print(syllables_with_corpus_stats)\n",
    "syllables_with_corpus_stats[\"pi\"].info\n",
    "\n",
    "#note: mention that frew and prob are new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d69e19df-e1b8-4d62-93b9-5cd9921849cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p|i|ɾ|u|t|a|b|ɡ|o|l|... (13 elements total)\n"
     ]
    }
   ],
   "source": [
    "phonemes = syllables.flatten()\n",
    "print(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d74536ce-2c78-40e2-84cf-faf7dd77aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p|t|a|b|ɡ|l|k|d|h\n",
      "{'features': ['-', '-', '+', '-', '-', '-', '-', '0', '-', '-', '-', '+', '-', '0', '+', '-', '-', '-', '-', '0', '-'], 'word_position_prob': {0: 0.17205350479361617, 1: 0.21734887192146507, 2: 0.28055571502382454, 3: 0.19685400998909236, 4: 0.04449164705206958, 5: 0.03743039210057983, 6: 0.018542970319765772, 7: 0.012859521212469143, 8: 0.007463114989379413, 9: 0.003961191802055227, 10: 0.003387106033641426, 11: 0.0014926229978758827, 12: 0.0020667087662896836, 13: 0.0006314943452551811, 14: 0.00040186003788966073, 15: 0.0002870428842069005, 16: 5.74085768413801e-05, 17: 0.0, 18: 5.74085768413801e-05, 19: 5.74085768413801e-05}}\n"
     ]
    }
   ],
   "source": [
    "from arc.io import read_phoneme_corpus\n",
    "corpus_phonemes = read_phoneme_corpus()\n",
    "\n",
    "phonemes_with_stats = phonemes.intersection(corpus_phonemes)\n",
    "print(phonemes_with_stats)\n",
    "print(phonemes_with_stats[\"p\"].info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b6e2702-7363-45b3-a289-2dc051d29570",
   "metadata": {},
   "source": [
    "## Evaluating your stream\n",
    "\n",
    "Again, we assume you have prepared your data into a list of syllables like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5e7334-cfc1-4fd4-bc76-08edfefabb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream:  pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo|pi|ɾu|ta|ba|ɡo|li|to|ku|da|ɡu|ki|bo\n",
      "\n",
      "rhythmicity indexes (PRIs) {'phon_1_son': 0.0, 'phon_1_back': 0.1693121693121693, 'phon_1_hi': 0.1693121693121693, 'phon_1_lab': 0.08465608465608465, 'phon_1_cor': 0.0, 'phon_1_cont': 0.0, 'phon_1_lat': 0.0, 'phon_1_nas': 0.0, 'phon_1_voi': 0.0, 'phon_2_back': 0.0, 'phon_2_hi': 0.0, 'phon_2_lo': 0.0, 'phon_2_lab': 0.0, 'phon_2_tense': 0.0, 'phon_2_long': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from arc import to_stream\n",
    "\n",
    "stream = ['pi', 'ɾu', 'ta', 'ba', 'ɡo', 'li', 'to', 'ku', 'da', 'ɡu', 'ki', 'bo']*streams.info['stream_length']\n",
    "\n",
    "stream = to_stream(stream)\n",
    "\n",
    "print(\"Stream: \", stream, end=\"\\n\\n\")\n",
    "print(\"rhythmicity indexes (PRIs)\", stream.info['rhythmicity_indexes'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e460fa40-acf5-48a9-b00a-abd0b8f5f970",
   "metadata": {},
   "source": [
    "As you can see, even with a custom lexicon, the randomization of a stream has an effect on the PRIs.\n",
    "\n",
    "This concludes our third and last tutorial. We hope you feel ready to use ARC, and help us extend it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5baf99-7704-462c-8e33-b3875930070c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
