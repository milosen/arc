{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0859a1-27fb-4496-b4fd-f87ab45ea567",
   "metadata": {},
   "source": [
    "# Tutorial 2\n",
    "\n",
    "We will load the words and generate a Lexicon with minimal feature overlap between the words. Then, we will follow up with the 2 main ways we can generate random streams, the `Word`-based and the `Syllable`-based stream generation.\n",
    "\n",
    "First, we load the words from tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75e7ba-dc5a-4e87-923a-c9423d498d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc import load_words\n",
    "\n",
    "words = load_words(\"arc_Words.json\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06413261-d35b-4c93-b6da-ff39cc51805b",
   "metadata": {},
   "source": [
    "Great, now we generate minimum-overlap lexicons with 4 words each. By default, the generator will yield 10 `Lexicon`s max. Let's generate 20 and print some info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491055a-9398-44dc-8b61-b457bf928f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.data import make_lexicon_generator\n",
    "\n",
    "lexicon_generator = make_lexicon_generator(words, n_words=6, max_yields=20)\n",
    "\n",
    "for lex in lexicon_generator:\n",
    "    print(lex, lex.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c5caf",
   "metadata": {},
   "source": [
    "Finally, we can generate a stream. The following should run quickly. If it doesn't, try reducing the number of words per lexicon or increasing the allowed rhythmicity index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994a9a6-9991-4089-bb50-cdf8dd8c01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.data import make_stream_from_words\n",
    "\n",
    "stream = make_stream_from_words(words, rand_mode=\"word\", n_words=4, max_rhythmicity=0.1)\n",
    "print(stream)\n",
    "\n",
    "for key, val in stream.info.items():\n",
    "    print(f\"{key}: {str(val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186f7db",
   "metadata": {},
   "source": [
    "If this runs quickly, then we can step it up and generate a complete set of compatible lexicons for our study. If `streams` is empty, try increasing the allowed maximum rythmicity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82199da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.data import make_compatible_streams\n",
    "streams = make_compatible_streams(words, n_words=4, max_rhythmicity=0.1)\n",
    "\n",
    "streams = [] if streams is None else streams\n",
    "\n",
    "for i, stream in enumerate(streams):\n",
    "    print(\"========= Stream Nr. \", i + 1, \" =========\")\n",
    "    print(\"\")\n",
    "    for key, val in stream.info.items():\n",
    "        print(f\"{key}: {str(val)}\")\n",
    "    print(\"lexicon cummulative overlap: \", stream.info[\"lexicon\"].info[\"cumulative_overlap\"])\n",
    "    print(\"\")\n",
    "    print(stream)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6eca6-5cea-4ce5-8739-524782c78fd8",
   "metadata": {},
   "source": [
    "A stream is a collection of syllables with repetition, i.e. a `Word` in our framework. It also come with some extra info about its feature rhythmicity indexes, the lexicons that were used to generate it, and how the stream was generated, i.e. whether the random generation is at the syllable or at the word level (rand_level={word, syllable}). At the word level, the words from a lexicon are randomized, but each word is left intact. Syllable level means that the words are further brocken down into syllables, and the syllables are shuffled across the whole lexicon, destroying word-level information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8408e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(streams[0].info[\"lexicon\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc",
   "language": "python",
   "name": "arc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
