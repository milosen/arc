{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cbd42-e4cc-4aeb-9636-cf7f21267d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b0859a1-27fb-4496-b4fd-f87ab45ea567",
   "metadata": {},
   "source": [
    "# Tutorial 2\n",
    "\n",
    "We will load the words and generate a Lexicon with minimal feature overlap between the words. Then, we will follow up with the 2 main ways we can generate random streams, the `Word`-based and the `Syllable`-based stream generation.\n",
    "\n",
    "First, we load the words from tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c75e7ba-dc5a-4e87-923a-c9423d498d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baːsuːheː|biːhoːseː|boːsiːhøː|buːhiːseː|buːhøːsiː|byːhoːʃeː|byːhøːzuː|bøːʃoːhiː|deːhøːfoː|deːçaːmuː|... (100 elements total)\n"
     ]
    }
   ],
   "source": [
    "from arc import load_words\n",
    "\n",
    "words = load_words(\"arc_results/arc_Words.json\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06413261-d35b-4c93-b6da-ff39cc51805b",
   "metadata": {},
   "source": [
    "Great, now we generate minimum-overlap lexicons with 4 words each. By default, the generator will yield 10 `Lexicon`s max. Let's generate 20 and print some info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6491055a-9398-44dc-8b61-b457bf928f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=1\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=2\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=3\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=4\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=5\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=6\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=7\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyːfuːhoː|kaːnyːfiː|byːhøːzuː|bøːʃoːhiː|loːkɛːvaː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "tyːfuːhoː|kaːnyːfiː|byːhøːzuː|bøːʃoːhiː|loːkɛːvaː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "ʃøːbyːhuː|fiːkɛːreː|zɛːheːbøː|foːløːɡyː|hiːpuːʃɛː|hoːʃeːpaː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "ʃøːpuːhiː|buːhøːsiː|faːdeːhoː|loːkɛːvaː|ɡɛːlyːfuː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "buːhøːsiː|faːdeːhoː|loːkɛːvaː|ɡɛːlyːfuː|ʃeːpoːhiː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyːfuːhoː|deːhøːfoː|faːɡiːluː|fiːloːkaː|hiːʃuːpeː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "ʃøːbyːhuː|fiːkɛːreː|zɛːheːbøː|foːløːɡyː|hiːpuːʃɛː|hoːʃeːpaː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "ʃøːbyːhuː|vaːniːkoː|fiːkɛːreː|zɛːheːbøː|hiːpuːʃɛː|hoːʃeːpaː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "kaːløːfyː|tyːfuːhoː|byːhøːzuː|loːkɛːvaː|fiːtoːheː|hiːpuːʃɛː|... (6 elements total) {'cumulative_overlap': 9}\n",
      "tyːfuːhoː|kaːnyːfiː|byːhøːzuː|bøːʃoːhiː|loːkɛːvaː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "ʃøːbyːhuː|vaːniːkoː|zɛːheːbøː|foːkɛːryː|hiːpuːʃɛː|hoːʃeːpaː|... (6 elements total) {'cumulative_overlap': 9}\n",
      "ʃøːbyːhuː|faːɡiːluː|zɛːheːbøː|fuːlyːkɛː|hiːpuːʃɛː|hoːʃeːpaː|... (6 elements total) {'cumulative_overlap': 9}\n",
      "tyːfuːhoː|doːheːfaː|fiːkɛːreː|foːlaːkøː|ɡɛːzøːmuː|hiːpuːʃɛː|... (6 elements total) {'cumulative_overlap': 9}\n",
      "tyːfuːhoː|deːhøːfoː|faːɡiːluː|fiːloːkaː|hiːʃuːpeː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 9}\n",
      "tyːfuːhoː|vaːniːkoː|doːheːfaː|fiːkɛːreː|ɡɛːzøːmuː|hiːpuːʃɛː|... (6 elements total) {'cumulative_overlap': 9}\n",
      "tyːfuːhoː|kaːnyːfiː|byːhøːzuː|bøːʃoːhiː|loːkɛːvaː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "ʃøːbyːhuː|fiːkɛːreː|zɛːheːbøː|foːløːɡyː|hiːpuːʃɛː|hoːʃeːpaː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "ʃøːpuːhiː|buːhøːsiː|faːdeːhoː|loːkɛːvaː|ɡɛːlyːfuː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 8}\n",
      "buːhøːsiː|faːdeːhoː|loːkɛːvaː|ɡɛːlyːfuː|ʃeːpoːhiː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 9}\n",
      "baːsuːheː|tyːfuːhoː|byːhøːzuː|køːlaːfiː|loːkɛːvaː|huːpaːzyː|... (6 elements total) {'cumulative_overlap': 9}\n"
     ]
    }
   ],
   "source": [
    "from arc.data import make_lexicon_generator\n",
    "\n",
    "lexicon_generator = make_lexicon_generator(words, n_words=6, max_yields=20)\n",
    "\n",
    "for lex in lexicon_generator:\n",
    "    print(lex, lex.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c5caf",
   "metadata": {},
   "source": [
    "Finally, we can generate a stream. The following should run quickly. If it doesn't, your try reducing the number of words per lexicon or increasing the allowed rhythmicity index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0994a9a6-9991-4089-bb50-cdf8dd8c01e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=1\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoːbeːsiːmyːtiːçaːzɛːheːbøːfoːkuːreːzɛːheːbøːmyːtiːçaːhoːbeːsiːfoːkuːreːmyːtiːçaːfoːkuːreːhoːbeːsiːzɛːheːbøːfoːkuːreːmyːtiːçaːzɛːheːbøːhoːbeːsiːzɛːheːbøːhoːbeːsiːmyːtiːçaːfoːkuːreːhoːbeːsiːfoːkuːreːzɛːheːbøːmyːtiːçaːfoːkuːreːhoːbeːsiːzɛːheːbøːmyːtiːçaːhoːbeːsiːfoːkuːreːmyːtiːçaːzɛːheːbøːfoːkuːreːzɛːheːbøːhoːbeːsiːmyːtiːçaːhoːbeːsiːmyːtiːçaːfoːkuːreːzɛːheːbøːhoːbeːsiːzɛːheːbøːfoːkuːreːmyːtiːçaːfoːkuːreːhoːbeːsiːmyːtiːçaːzɛːheːbøːmyːtiːçaːhoːbeːsiːzɛːheːbøːfoːkuːreːzɛːheːbøːhoːbeːsiːfoːkuːreːmyːtiːçaːzɛːheːbøːmyːtiːçaːfoːkuːreːhoːbeːsiːzɛːheːbøːfoːkuːreːhoːbeːsiːmyːtiːçaːzɛːheːbøːfoːkuːreːmyːtiːçaːhoːbeːsiːmyːtiːçaːfoːkuːreːzɛːheːbøːhoːbeːsiːfoːkuːreːzɛːheːbøːmyːtiːçaːhoːbeːsiːfoːkuːreːmyːtiːçaːhoːbeːsiːzɛːheːbøːmyːtiːçaːzɛːheːbøːhoːbeːsiːfoːkuːreːhoːbeːsiːzɛːheːbøːmyːtiːçaːfoːkuːreːmyːtiːçaːhoːbeːsiːfoːkuːreːzɛːheːbøːmyːtiːçaːzɛːheːbøːfoːkuːreːhoːbeːsiːmyːtiːçaːfoːkuːreːhoːbeːsiːzɛːheːbøːhoːbeːsiːfoːkuːreːmyːtiːçaːzɛːheːbøːfoːkuːreːzɛːheːbøːhoːbeːsiːmyːtiːçaːfoːkuːreːmyːtiːçaːzɛːheːbøːhoːbeːsiːfoːkuːreːzɛːheːbøːmyːtiːçaːhoːbeːsiːzɛːheːbøːfoːkuːreːhoːbeːsiːmyːtiːçaːfoːkuːreːhoːbeːsiːmyːtiːçaːzɛːheːbøːfoːkuːreːmyːtiːçaːhoːbeːsiːzɛːheːbøːhoːbeːsiːfoːkuːreːzɛːheːbøːmyːtiːçaːzɛːheːbøːhoːbeːsiːfoːkuːreːmyːtiːçaːhoːbeːsiːmyːtiːçaːfoːkuːreːzɛːheːbøːmyːtiːçaːhoːbeːsiːzɛːheːbøːfoːkuːreːmyːtiːçaːzɛːheːbøːhoːbeːsiːfoːkuːreːzɛːheːbøːmyːtiːçaːfoːkuːreːhoːbeːsiːfoːkuːreːhoːbeːsiːzɛːheːbøːmyːtiːçaːhoːbeːsiːmyːtiːçaːzɛːheːbøːfoːkuːreːzɛːheːbøːhoːbeːsiːmyːtiːçaːfoːkuːreːhoːbeːsiːzɛːheːbøːfoːkuːreːmyːtiːçaːzɛːheːbøːfoːkuːreːmyːtiːçaːhoːbeːsiːzɛːheːbøːmyːtiːçaːhoːbeːsiːfoːkuːreːmyːtiːçaːzɛːheːbøːfoːkuːreːhoːbeːsiːmyːtiːçaːfoːkuːreːzɛːheːbøːhoːbeːsiːmyːtiːçaːhoːbeːsiːfoːkuːreːzɛːheːbøːhoːbeːsiːzɛːheːbøːmyːtiːçaːfoːkuːreː\n",
      "rhythmicity_indexes: [0.1, 0.0, 0.0, 0.09649122807017543, 0.0912280701754386, 0.0, 0.0, 0.0, 0.015789473684210527, 0.014035087719298246, 0.02280701754385965, 0.0, 0.0, 0.0]\n",
      "lexicon: foːkuːreː|hoːbeːsiː|myːtiːçaː|zɛːheːbøː|... (4 elements total)\n",
      "rand_mode: word\n"
     ]
    }
   ],
   "source": [
    "from arc.data import make_stream_from_words\n",
    "\n",
    "stream = make_stream_from_words(words, rand_mode=\"word\", n_words=4, max_rhythmicity=0.1)\n",
    "print(stream)\n",
    "\n",
    "for key, val in stream.info.items():\n",
    "    print(f\"{key}: {str(val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186f7db",
   "metadata": {},
   "source": [
    "If this runs quickly, then we can step it up and generate a complete set of compatible lexicons for our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82199da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=1\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=2\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=1\n",
      "WARNING:root:Increasing allowed overlaps: MAX_PAIRWISE_OVERLAP=1, MAX_CUMULATIVE_OVERLAP=2\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because no good word-randomized stream for Lexicon 1 was found.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n",
      "WARNING:root:Dropping Lexicons because they have overlapping syllables.\n"
     ]
    }
   ],
   "source": [
    "from arc.data import make_compatible_streams\n",
    "streams = make_compatible_streams(words, n_words=4, max_rhythmicity=0.09)\n",
    "\n",
    "for i, stream in enumerate(streams):\n",
    "    print(\"========= Stream Nr. \", i + 1, \" =========\")\n",
    "    print(\"\")\n",
    "    for key, val in stream.info.items():\n",
    "        print(f\"{key}: {str(val)}\")\n",
    "    print(\"lexicon cummulative overlap: \", stream.info[\"lexicon\"].info[\"cumulative_overlap\"])\n",
    "    print(\"\")\n",
    "    print(stream)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8408e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba0213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc",
   "language": "python",
   "name": "arc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
