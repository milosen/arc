{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0859a1-27fb-4496-b4fd-f87ab45ea567",
   "metadata": {},
   "source": [
    "# Tutorial 2\n",
    "\n",
    "We will load the words and generate a Lexicon with minimal feature overlap between the words. Then, we will follow up with the 2 main ways we can generate random streams, the `Word`-based and the `Syllable`-based stream generation.\n",
    "\n",
    "## Lexicon\n",
    "\n",
    "First, we load the words from tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75e7ba-dc5a-4e87-923a-c9423d498d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc import load_words\n",
    "\n",
    "words = load_words(\"words.json\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06413261-d35b-4c93-b6da-ff39cc51805b",
   "metadata": {},
   "source": [
    "Great, now we generate minimum-overlap lexicons with 4 words each. By default, the function will generate 5 `Lexicon`s max. Let's generate 2 and print some info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491055a-9398-44dc-8b61-b457bf928f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.generation.lexicons import make_lexicons_from_words\n",
    "from arc import Lexicon\n",
    "from typing import Tuple\n",
    "\n",
    "lexicons: Tuple[Lexicon, ...] = make_lexicons_from_words(words, n_lexicons=2)\n",
    "\n",
    "for lexicon in lexicons:\n",
    "    print(lexicon, lexicon.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c5caf",
   "metadata": {},
   "source": [
    "By default, Lexicons with the minimum possible cumulative overlap between the word features will be generated first, starting at zero overlap. If it is not possible to generate all the requested Lexicons with the given parameters, the allowed overlap will be increased, which will be indicated by a warning message.\n",
    "\n",
    "This process will be repeated, until any of the following statements is true\n",
    "- the requested number of Lexicons has been generated\n",
    "- the maximum allowed overlap is reached (set via `max_overlap`)\n",
    "- the set of all word combinations is exhausted\n",
    "\n",
    "If one or more Lexicons is returned, their info fields hold the cumulative overlap between all word pairs that is achieved by the Lexicon as well as the maximum pairwise overlap used.\n",
    "\n",
    "## Stream\n",
    "\n",
    "### Single Stream\n",
    "\n",
    "The stream generation internally generates a Lexicon first, and then a Stream based on that. The following cell, however, generates a stream directly from words for convenience. The cell should execute quickly. If it doesn't, try reducing the number of words per lexicon or increasing the allowed rhythmicity index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd7657-fb12-471b-b7b7-c391d9559f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994a9a6-9991-4089-bb50-cdf8dd8c01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.generation.stream import make_stream_from_words\n",
    "\n",
    "stream = make_stream_from_words(words, rand_mode=\"word\", n_words=4, max_rhythmicity=0.1)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(stream)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "for key, val in stream.info.items():\n",
    "    print(f\"{key}: {str(val)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186f7db",
   "metadata": {},
   "source": [
    "As you can see, the `.info` field holds some useful information about the generated stream, i.e. which Lexicon has been used to generate it, the rythmicity indexes achieved for each feature, and which randomization mode has been used. The randomization mode can be `syllable` or `word`. It can be immediately varified that the randomization mode is `word`, since the individual words of the Lexicon can be recognized in the stream. Contrastingly, syllable level randomization means that the words are further brocken down into syllables, and the syllables are shuffled across the whole lexicon, destroying word-level information.\n",
    "\n",
    "Next, we will use this distinction to generate a compatible set of streams for testing statistical learning hypotheses.\n",
    "\n",
    "### Set of Compatible Streams\n",
    "\n",
    "If this runs quickly, then we can step it up and generate a complete set of compatible lexicons for our study. If `streams` is empty, try increasing the allowed maximum rythmicity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82199da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.generation.stream import make_compatible_streams\n",
    "streams = make_compatible_streams(words, n_words=4, max_rhythmicity=0.1)\n",
    "\n",
    "for i, stream in enumerate(streams):\n",
    "    print(\"========= Stream Nr. \", i + 1, \" =========\")\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    print(stream)\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    for key, val in stream.info.items():\n",
    "        print(f\"{key}: {str(val)}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8408e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ae373-3aea-4d63-a182-1c7ef684aa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576d9a4-34a2-4ddb-8872-2c74b50ec1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc",
   "language": "python",
   "name": "arc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
